import argparse
import torch
import torchxrayvision as xrv
from torchvision import transforms
from PIL import Image
import numpy as np
import cv2
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import pandas as pd
import torch.nn as nn
import os
import torch.nn.functional as F
import torchvision.models as models
import boto3
from time import gmtime, strftime
import csv
from datetime import datetime, timezone
import pytz
import io

# !!! ì„¤ì • !!!
# ---------------------------------
model_path = 'models/model.pth'  # ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ
#image_path = '87ddbd40-b218-4bfd-9a82-2ea252e08c1e.jpg'  # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œì»¬ ê²½ë¡œ
# ---------------------------------
bucket_name = 'say1-4team-bucket'  # S3 ë²„í‚· ì´ë¦„
s3_key = 'cxr-pneumonia-4/preprocessed-3/test/0/00000217_000.png' # S3ì—ì„œ ê°€ì ¸ì˜¬ íŒŒì¼ ê²½ë¡œ
s3_raw_key = 'cxr-pneumonia-4/raw/test/0/00000217_000.png' # ì›ë³¸ ì´ë¯¸ì§€ S3 ê²½ë¡œ
upload_key = f'cxr-pneumonia-4/upload-test/{s3_key}' # S3ì— ì—…ë¡œë“œí•  ê²½ë¡œ
image_path = 'test_image.jpg'  # ë¡œì»¬ì— ì €ì¥í•  ê²½ë¡œ
raw_image_path = 'test_raw_image.jpg'  # ì›ë³¸ ì´ë¯¸ì§€ ë¡œì»¬ ì €ì¥ ê²½ë¡œ
# ---------------------------------




# --- 1) ëª¨ë¸ ìœ í‹¸ í•¨ìˆ˜ ---
def get_device():
    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def create_model(num_classes, device):
    # xrv.models.ResNetìœ¼ë¡œ CXR ì‚¬ì „í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©
    model = models.resnet50(weights='IMAGENET1K_V1')
    # í”„ë¡œì íŠ¸ í´ë˜ìŠ¤ ìˆ˜ì— ë§ê²Œ ë§ˆì§€ë§‰ FC ë ˆì´ì–´ êµì²´
    in_features = model.fc.in_features
    model.fc = nn.Linear(in_features, num_classes)

    model.op_threshs = None
    # í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    state = torch.load(model_path, map_location=device)
    model.load_state_dict(state, strict=False)  # strict=Falseë¡œ ë³€ê²½í•˜ì—¬ ì¼ë¶€ í‚¤ê°€ ì¼ì¹˜í•˜ì§€ ì•Šì•„ë„ ë¡œë“œ ê°€ëŠ¥
    model = model.to(device).eval()
    return model

# --- 2) VanillaGradientExplainer í´ë˜ìŠ¤ ---
class VanillaGradientExplainer:
    def __init__(self, model, device):
        self.model = model.eval().to(device)
        self.device = device
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),  # ResNet ì…ë ¥ í¬ê¸°
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

    def compute_vanilla_gradients(self, image, target_class=None):
        if isinstance(image, np.ndarray):
            image = Image.fromarray(image)
        
        input_tensor = self.transform(image).unsqueeze(0).to(self.device)
        input_tensor.requires_grad_(True)
        
        # Forward pass
        output = self.model(input_tensor)
        
        # ì˜ˆì¸¡ ê²°ê³¼ ê³„ì‚°
        probs = F.softmax(output, dim=1)
        prediction = torch.argmax(probs, dim=1).item()
        confidence = probs[0, prediction].item()
        
        # ëª©í‘œ í´ë˜ìŠ¤ ì„¤ì •
        if target_class is None:
            target_class = prediction
        
        # Backward pass - ëª©í‘œ í´ë˜ìŠ¤ì— ëŒ€í•œ gradient ê³„ì‚°
        self.model.zero_grad()
        target_score = output[0, target_class]
        target_score.backward()
        
        # Gradient ì¶”ì¶œ ë° ì°¨ì› ì²˜ë¦¬
        gradients = input_tensor.grad.data.squeeze().cpu().numpy()
        
        # ë‹¤ì±„ë„ì¸ ê²½ìš° (RGB ë“±) í‰ê·  ë˜ëŠ” ì²« ë²ˆì§¸ ì±„ë„ë§Œ ì‚¬ìš©
        if gradients.ndim == 3:
            gradients = np.mean(gradients, axis=0)  # ì±„ë„ë³„ í‰ê· 
        elif gradients.ndim == 1:
            # 1Dì¸ ê²½ìš° 224x224ë¡œ reshape
            gradients = gradients.reshape(224, 224)
        
        return gradients, prediction, confidence

    def visualize(self, raw_image, heatmap, alpha=0.4, save_path=None, save_to_s3=False):
        # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ numpy arrayë¡œ ë³€í™˜
        raw_img_np = np.array(raw_image.convert('RGB'))
        # heatmapì„ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ì¶° ë¦¬ì‚¬ì´ì¦ˆ
        H, W = raw_img_np.shape[:2]
        hm_uint8 = (heatmap * 255).astype(np.uint8)
        hm_resized = cv2.resize(hm_uint8, (W, H))
        cmap = cv2.applyColorMap(hm_resized, cv2.COLORMAP_HOT)
        overlay = cv2.addWeighted(raw_img_np, 1 - alpha, cmap, alpha, 0)

        # save or show
        fig, ax = plt.subplots(figsize=(6, 6))
        ax.axis('off')
        ax.imshow(overlay)

        if save_to_s3:
            # ë©”ëª¨ë¦¬ì—ì„œ S3ë¡œ ì—…ë¡œë“œ
            s3 = boto3.client('s3')
            try:
                buffer = io.BytesIO()
                fig.savefig(buffer, format='png', bbox_inches='tight', pad_inches=0)
                buffer.seek(0)
                s3.upload_fileobj(buffer, bucket_name, upload_key)
                plt.close(fig)
                print(f"âœ… S3ì— íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ: s3://{bucket_name}/{upload_key}")
            except Exception as e:
                print(f"âŒ S3ì— íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
                raise
        else:
            plt.show()
        
        if save_path:
            # ë¡œì»¬ì— ì €ì¥
            os.makedirs(os.path.dirname(save_path) or '.', exist_ok=True)
            fig.savefig(save_path, bbox_inches='tight', pad_inches=0)
            plt.close(fig)
            print(f"Saved gradient visualization to '{save_path}'")
            
        else:
            plt.show()


# --- 3) ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ ---
def main():
    p = argparse.ArgumentParser()
    # p.add_argument('--model-path', required=True)
    # p.add_argument('--image-path', required=True)
    p.add_argument('--num-classes', type=int, default=3)
    p.add_argument('--output', type=str, default='grad.png')
    args = p.parse_args()

    s3 = boto3.client('s3')
    try:
        s3.download_file(bucket_name, s3_key, image_path)
        print(f"âœ… S3ì—ì„œ segment íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {image_path}")
    except Exception as e:
        print(f"âŒ S3ì—ì„œ segment íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise
    try:
        s3.download_file(bucket_name, s3_raw_key, raw_image_path)
        print(f"âœ… S3ì—ì„œ raw íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {raw_image_path}\n")
    except Exception as e:
        print(f"âŒ S3ì—ì„œ raw íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise

    # ì¥ì¹˜ ì„¤ì • & ëª¨ë¸ ë¡œë“œ
    device = get_device()
    model = create_model(args.num_classes, device)
    # model.load_state_dict(torch.load(args.model_path, map_location=device))
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = Image.open(image_path).convert('RGB')
    raw_image = Image.open(raw_image_path).convert('RGB')

    # Vanilla Gradient ê³„ì‚° ë° ì‹œê°í™”
    explainer = VanillaGradientExplainer(model, device)
    gradients, prediction, confidence = explainer.compute_vanilla_gradients(image)
    # ì ˆëŒ“ê°’ í›„ 0-1 ì •ê·œí™”
    gradients = np.abs(gradients)
    # 0-1 ì¬ì •ê·œí™”
    if gradients.max() > gradients.min():
        grad = (gradients - gradients.min()) / (gradients.max() - gradients.min())
    # ë…¸ì´ì¦ˆ ì œê±°ë¥¼ ìœ„í•œ ì„ê³„ê°’ ì ìš© (ìƒìœ„ 5%ë§Œ ìœ ì§€)
    thresh = np.percentile(grad, 95)
    grad = np.where(grad >= thresh, grad, 0)
    # ë¶€ë“œëŸ¬ìš´ ì‹œê°í™”ë¥¼ ìœ„í•œ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
    grad = cv2.GaussianBlur(grad, (5, 5), 1.0)

    # ì‹œê°í™” ì €ì¥
    explainer.visualize(raw_image, grad, save_path=None, save_to_s3=True)
    
    # ë¡œì»¬ ì €ì¥ í™•ì¸ ë° ì ˆëŒ€ ê²½ë¡œ ì¶œë ¥
    output_path = args.output
    if os.path.isfile(output_path):
        abs_path = os.path.abspath(output_path)
        print(f"âœ… ë¡œì»¬ íŒŒì¼ ì ˆëŒ€ ê²½ë¡œ {abs_path}")
    else:
        print(f"âŒ ë¡œì»¬ íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {output_path}")
        
    # CSV íŒŒì¼ ì‘ì„±
    csv_filename = 'prediction_results.csv'
    csv_s3_key = 'cxr-pneumonia-4/upload-test/prediction_results.csv'
    kst = pytz.timezone('Asia/Seoul')
    # í˜„ì¬ ì‹œê°„ (UTC -> KST ë³€í™˜)
    utc_now = datetime.now(timezone.utc)  # ê¶Œì¥ë˜ëŠ” ë°©ì‹ìœ¼ë¡œ UTC ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
    current_time = utc_now.astimezone(kst).strftime("%Y-%m-%d-%H-%M-%S")
    # current_time = strftime("%Y-%m-%d-%H-%M-%S", gmtime())
    csv_data = [
        {
            'time_KST': current_time,
            'required_original': s3_raw_key,
            'required_segmented': s3_key,
            'predicted_class': prediction,
            'confidence': confidence,
            'uploaded_filename': upload_key
        }
    ]

    # ë¡œì»¬ì— CSV íŒŒì¼ ìƒì„±
    with open(csv_filename, mode='w', newline='') as csv_file:
        writer = csv.DictWriter(csv_file, fieldnames=['time_KST', 'required_original', 'required_segmented', 'predicted_class', 'confidence', 'uploaded_filename'])
        writer.writeheader()
        writer.writerows(csv_data)
    print(f"âœ… CSV íŒŒì¼ ìƒì„± ì™„ë£Œ: {csv_filename}")

    # S3ì— CSV íŒŒì¼ ì—…ë¡œë“œ
    try:
        with open(csv_filename, 'rb') as f:
            s3.upload_fileobj(f, bucket_name, csv_s3_key)
        print(f"âœ… S3ì— CSV íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ: s3://{bucket_name}/{csv_s3_key}")
    except Exception as e:
        print(f"âŒ S3ì— CSV íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise
    
    # ì˜ˆì¸¡ ê²°ê³¼ë„ í•¨ê»˜ ì¶œë ¥
    if prediction == 0:
        print(f"\n>>> ì˜ˆì¸¡ í´ë˜ìŠ¤: ì •ìƒ, confidence: {confidence:.3f}")
    elif prediction == 1:
        print(f"\n>>> ì˜ˆì¸¡ í´ë˜ìŠ¤: íë ´, confidence: {confidence:.3f}")
    elif prediction == 2:
        print(f"\n>>> ì˜ˆì¸¡ í´ë˜ìŠ¤: ê¸°íƒ€, confidence: {confidence:.3f}")
    print(f"ğŸ’¾ ì‹œê°í™” ê²°ê³¼ ì €ì¥ íŒŒì¼ëª…: {args.output}")
    print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ CSV íŒŒì¼ëª…: {csv_filename}\n")

if __name__ == "__main__":
    main()